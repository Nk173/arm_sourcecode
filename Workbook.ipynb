{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import IM_rank_correlations as IMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ranks_matrix = IMR.ranks(IMR.scores_matrix, IMR.measures_arr);\n",
    "measures_arr = ranks_matrix.measures_arr;\n",
    "measures_dict = ranks_matrix.measures_dict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ranks_matrix.compute_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_redundant(measures_arr):\n",
    "#     print(len(measures_arr))\n",
    "    for i in range(len(measures_arr)):\n",
    "        for j in range(len(measures_arr)):\n",
    "            if (i > j):\n",
    "                if (np.around(ranks_matrix.corr_spearman[i][j], 3) == 1):\n",
    "#                     print(measures_arr[i],measures_arr[j]);\n",
    "                    return(j);\n",
    "\n",
    "# find_redundant(measures_arr)\n",
    "\n",
    "while find_redundant(measures_arr):\n",
    "    i = find_redundant(measures_arr);\n",
    "    measures_dict, measures_arr = ranks_matrix.remove_outliers(i);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_outlier(clusters):\n",
    "    arr = []\n",
    "    for i in range(len(clusters)):\n",
    "        if len(clusters[i]) == 1:\n",
    "            arr.append(clusters[i]);\n",
    "    return np.array(arr);\n",
    "\n",
    "\n",
    "# while len(find_outlier(clusters)):\n",
    "#     idx_outliers = find_outlier(clusters);\n",
    "#     print(measures_arr[idx_outliers]);\n",
    "#     measures_dict, measures_arr = ranks_matrix.remove_outliers(idx_outliers);\n",
    "#     clusters = ranks_matrix.form_clusters(n_clusters);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [ 0  4  6 12]\n",
      "['recall' 'support' 'kulczynsky_1' 'cosine']\n",
      "16 [ 1  3  9 10 11 16 17 19 20 21 22 23 28 29 32 34]\n",
      "['mutual_information' 'accuracy' 'relative_risk' 'novelty' 'yules_y'\n",
      " 'conviction' 'information_gain' 'klosgen' 'zhang'\n",
      " 'normalized_mutual_information' 'one_way_support' 'two_way_support'\n",
      " 'kappa' 'putative_causal_dependency' 'collective_strength' 'dependency']\n",
      "1 [2]\n",
      "['negative_reliability']\n",
      "7 [ 5 13 14 15 18 30 31]\n",
      "['confidence_causal' 'least_contradiction' 'confirm_descriptive'\n",
      " 'confirm_causal' 'laplace_correction' 'example_counterexample_rate'\n",
      " 'confirmed_confidence_causal']\n",
      "1 [7]\n",
      "['coverage']\n",
      "1 [8]\n",
      "['prevalence']\n",
      "1 [24]\n",
      "['implication_index']\n",
      "2 [25 33]\n",
      "['gini_index' 'j_measure']\n",
      "1 [26]\n",
      "['goodman_kruskal']\n",
      "1 [27]\n",
      "['leverage']\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 10;\n",
    "clusters = ranks_matrix.form_clusters(n_clusters);\n",
    "for cluster in clusters:\n",
    "    print(len(cluster), cluster);\n",
    "    print(measures_arr[cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ranks_matrix.measures_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#removing all measures except the ones in cluster 1 (16 measures)\n",
    "to_remove = np.empty(0, int);\n",
    "\n",
    "for cluster in clusters:\n",
    "    if not (len(cluster) == 16):\n",
    "        to_remove = np.append(to_remove, cluster);\n",
    "\n",
    "measures_dict, measures_arr = ranks_matrix.remove_outliers(to_remove);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['recall', 'support', 'kulczynsky_1', 'cosine'], \n",
      "      dtype='<U29'), array(['mutual_information', 'accuracy', 'relative_risk', 'novelty',\n",
      "       'yules_y', 'conviction', 'information_gain', 'klosgen', 'zhang',\n",
      "       'normalized_mutual_information', 'one_way_support',\n",
      "       'two_way_support', 'kappa', 'putative_causal_dependency',\n",
      "       'collective_strength', 'dependency'], \n",
      "      dtype='<U29'), array(['confidence_causal', 'least_contradiction', 'confirm_descriptive',\n",
      "       'confirm_causal', 'laplace_correction',\n",
      "       'example_counterexample_rate', 'confirmed_confidence_causal'], \n",
      "      dtype='<U29'), array(['negative_reliability', 'coverage', 'prevalence',\n",
      "       'implication_index', 'gini_index', 'j_measure', 'goodman_kruskal',\n",
      "       'leverage'], \n",
      "      dtype='<U29')]\n"
     ]
    }
   ],
   "source": [
    "misc_cluster = np.array([], int);\n",
    "misc_cluster = np.append(misc_cluster, clusters[2]);\n",
    "misc_cluster = np.append(misc_cluster, clusters[4]);\n",
    "misc_cluster = np.append(misc_cluster, clusters[5]);\n",
    "misc_cluster = np.append(misc_cluster, clusters[6]);\n",
    "misc_cluster = np.append(misc_cluster, clusters[7]);\n",
    "misc_cluster = np.append(misc_cluster, clusters[8]);\n",
    "misc_cluster = np.append(misc_cluster, clusters[9]);\n",
    "\n",
    "clusters_new = [];\n",
    "clusters_new.append(clusters[0]);\n",
    "clusters_new.append(clusters[1]);\n",
    "clusters_new.append(clusters[3]);\n",
    "clusters_new.append(misc_cluster);\n",
    "\n",
    "clusters_new = np.array(clusters_new);\n",
    "clusters = clusters_new;\n",
    "\n",
    "# print(clusters_new)\n",
    "print([measures_arr[clusters_new[i]] for i in range(len(clusters_new))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [ 0  4  6 12]\n",
      "['recall' 'support' 'kulczynsky_1' 'cosine']\n",
      "16 [ 1  3  9 10 11 16 17 19 20 21 22 23 28 29 32 34]\n",
      "['mutual_information' 'accuracy' 'relative_risk' 'novelty' 'yules_y'\n",
      " 'conviction' 'information_gain' 'klosgen' 'zhang'\n",
      " 'normalized_mutual_information' 'one_way_support' 'two_way_support'\n",
      " 'kappa' 'putative_causal_dependency' 'collective_strength' 'dependency']\n",
      "7 [ 5 13 14 15 18 30 31]\n",
      "['confidence_causal' 'least_contradiction' 'confirm_descriptive'\n",
      " 'confirm_causal' 'laplace_correction' 'example_counterexample_rate'\n",
      " 'confirmed_confidence_causal']\n",
      "8 [ 2  7  8 24 25 33 26 27]\n",
      "['negative_reliability' 'coverage' 'prevalence' 'implication_index'\n",
      " 'gini_index' 'j_measure' 'goodman_kruskal' 'leverage']\n"
     ]
    }
   ],
   "source": [
    "for cluster in clusters:\n",
    "    print(len(cluster), cluster);\n",
    "    print(measures_arr[cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import measure_classification as mc;\n",
    "import compute_invariance as compute_invariance;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "property_dict = compute_invariance.compute_property_vectors(measures_dict);\n",
    "X,Y = mc.initialize_X_Y(measures_arr, property_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 805)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = mc.form_X(property_dict, measures_dict, X);\n",
    "Y = mc.assign_clusters_to_Y(clusters, Y);\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import scipy.spatial.distance as ssd\n",
    "# import scipy.misc as sm;\n",
    "# import numpy as np;\n",
    "\n",
    "# for c in range(len(clusters)):\n",
    "#     n= sm.comb(len(clusters[c]),2);\n",
    "#     arr = np.zeros(n, float);\n",
    "# #     print(c)\n",
    "#     k=0;\n",
    "#     for i in clusters[c]:\n",
    "#         for j in clusters[c]:\n",
    "#             if (i > j):\n",
    "# #                 print(measures_arr[i], measures_arr[j]);\n",
    "# #                 print(X[i], X[j])\n",
    "#                 arr[k] = ssd.hamming(X[i], X[j]);\n",
    "#                 k += 1;\n",
    "#     print(np.average(arr))\n",
    "# # print(measures_arr[clusters[0][1]], measures_arr[clusters[0][2]])\n",
    "# # ssd.jaccard(X[clusters[0][1]], X[clusters[0][4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742857142857\n"
     ]
    }
   ],
   "source": [
    "predictions, tree_classifier = mc.classify_decision_tree(X,Y, criterion='entropy');\n",
    "print(tree_classifier.score(X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc.export_to_pdf(tree_classifier, n_clusters, len(measures_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# measures_arr[(X[:,0] == 0) & ((X[:,1] == 0)) & ((X[:,2] == 0)) & ((X[:,4] == 0)) & ((X[:,5] == 0)) & ((X[:,6] == 0)) & ((X[:,7] == 0))]\n",
    "measures_arr[(X[:,36] == 1) & ((X[:,48] == -1)) & ((X[:,111] == -1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.around(ranks_matrix.corr_spearman[measures_dict['example_counterexample_rate'], measures_dict['laplace_correction']], 3)\n",
    "\n",
    "# X = np.delete(X, 3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ranks_matrix.show_dendrogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# a = np.empty((len(X[0,:]),len(clusters)), float);\n",
    "# for p in range(len(clusters)):\n",
    "#     for i in range(len(X[0,:])):\n",
    "# #         a[i][p] = np.sum(X[clusters[p],i])/len(clusters[p]);\n",
    "#         a[i][p] = np.sum(X[clusters[p],i]);\n",
    "#         print(a[i][p])\n",
    "# #     print('----')\n",
    "# # a = (1 + a)/2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15,30], ncols=1, nrows=1);\n",
    "plt.imshow(a, interpolation='none', cmap=plt.cm.RdBu);\n",
    "# plt.colorbar();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.misc as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "7 + (2 * sm.comb(7,2)) + (4 * sm.comb(7,3)) + (8 * sm.comb(7,4)) + (16 * sm.comb(7,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "7 + (2 * sm.comb(7,2)) + (4 * sm.comb(7,3)) + (8 * sm.comb(7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "inv = ['P2', 'P3', 'O1', 'O2', 'O3', 'O4', 'O5'];\n",
    "for i,j,l,m,n in itertools.combinations(range(7),5):\n",
    "    print(inv[i] + ' and ' + inv[j] + ' and ' + inv[l] + ' and ' + inv[m] + ' and ' + inv[n]);\n",
    "    print(inv[i] + ' or ' + inv[j] + ' and ' + inv[l] + ' and ' + inv[m] + ' and ' + inv[n]);\n",
    "    print(inv[i] + ' and ' + inv[j] + ' or ' + inv[l] + ' and ' + inv[m] + ' and ' + inv[n]);\n",
    "    print(inv[i] + ' or ' + inv[j] + ' or ' + inv[l] + ' and ' + inv[m] + ' and ' + inv[n]);\n",
    "\n",
    "    print(inv[i] + ' and ' + inv[j] + ' and ' + inv[l] + ' or ' + inv[m] + ' and ' + inv[n]);\n",
    "    print(inv[i] + ' or ' + inv[j] + ' and ' + inv[l] + ' or ' + inv[m] + ' and ' + inv[n]);\n",
    "    print(inv[i] + ' and ' + inv[j] + ' or ' + inv[l] + ' or ' + inv[m] + ' and ' + inv[n]);\n",
    "    print(inv[i] + ' or ' + inv[j] + ' or ' + inv[l] + ' or ' + inv[m] + ' and ' + inv[n]);\n",
    "\n",
    "    print(inv[i] + ' and ' + inv[j] + ' and ' + inv[l] + ' and ' + inv[m] + ' or ' + inv[n]);\n",
    "    print(inv[i] + ' or ' + inv[j] + ' and ' + inv[l] + ' and ' + inv[m] + ' or ' + inv[n]);\n",
    "    print(inv[i] + ' and ' + inv[j] + ' or ' + inv[l] + ' and ' + inv[m] + ' or ' + inv[n]);\n",
    "    print(inv[i] + ' or ' + inv[j] + ' or ' + inv[l] + ' and ' + inv[m] + ' or ' + inv[n]);\n",
    "\n",
    "    print(inv[i] + ' and ' + inv[j] + ' and ' + inv[l] + ' or ' + inv[m] + ' or ' + inv[n]);\n",
    "    print(inv[i] + ' or ' + inv[j] + ' and ' + inv[l] + ' or ' + inv[m] + ' or ' + inv[n]);\n",
    "    print(inv[i] + ' and ' + inv[j] + ' or ' + inv[l] + ' or ' + inv[m] + ' or ' + inv[n]);\n",
    "    print(inv[i] + ' or ' + inv[j] + ' or ' + inv[l] + ' or ' + inv[m] + ' or ' + inv[n]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
