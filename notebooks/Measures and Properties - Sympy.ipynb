{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "from sympy.solvers import solveset\n",
    "print(sp.__version__)\n",
    "from sympy.calculus.singularities import is_monotonic\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pretty printing\n",
    "sp.init_printing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#frequency counts\n",
    "f11, f01, f10, f00, N = sp.symbols('f11, f01, f10, f00, N', nonnegative=True, real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#marginals\n",
    "P_a, P_b = sp.symbols('P_a, P_b', nonnegative = True)\n",
    "\n",
    "P_aprime = 1 - P_a\n",
    "P_bprime = 1 - P_b\n",
    "\n",
    "#Joint probabilities\n",
    "P_ab, P_abprime, P_aprimeb, P_aprimebprime = sp.symbols('P_ab, P_abprime, P_aprimeb, P_aprimebprime', nonnegative = True)\n",
    "\n",
    "\n",
    "#Conditionals\n",
    "P_agivenb = P_ab / P_b\n",
    "P_bgivena = P_ab / P_a\n",
    "P_bgivenaprime = P_aprimeb / P_aprime\n",
    "P_bprimegivena = 1 - P_bgivena\n",
    "P_bprimegivenaprime = 1 - P_bgivenaprime\n",
    "P_agivenbprime = P_abprime / P_bprime\n",
    "P_aprimegivenbprime = 1 - P_agivenbprime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Measures = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Measures = {}\n",
    "\n",
    "#Accuracy\n",
    "Measures['accuracy'] = P_ab + P_aprimebprime\n",
    "\n",
    "#Certainty Factor\n",
    "Measures['certainty_factor'] = 1 - P_abprime / (P_a * P_bprime)\n",
    "\n",
    "#Confidence\n",
    "Measures['confidence'] = P_bgivena\n",
    "\n",
    "#Confidence Causal\n",
    "Measures['confidence_causal'] = (P_bgivena + P_aprimegivenbprime)/2\n",
    "\n",
    "#Confirm Causal\n",
    "Measures['confirm_causal'] = P_ab + P_aprimebprime - 2 * P_abprime\n",
    "\n",
    "#Confirm Descriptive\n",
    "Measures['confirm_descriptive'] = P_ab - P_abprime\n",
    "\n",
    "#Conviction\n",
    "Measures['conviction'] = (P_a * P_bprime) / P_abprime\n",
    "\n",
    "#Cosine\n",
    "Measures['cosine'] = P_ab / sp.sqrt(P_a * P_b)\n",
    "\n",
    "#Coverage\n",
    "Measures['coverage'] = P_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Measures = {}\n",
    "\n",
    "#F - Measure\n",
    "Measures['f_measure'] = (2 * P_agivenb * P_bgivena) / (P_agivenb + P_bgivena)\n",
    "\n",
    "#Ganascia\n",
    "Measures['ganascia'] = 2 * P_bgivena - 1\n",
    "\n",
    "#Gini Index\n",
    "Measures['gini_index'] = P_a * (P_bgivena**2 + P_bprimegivena**2) + P_aprime * (P_bgivenaprime**2 + P_bprimegivenaprime**2) - P_b**2 - P_bprime**2\n",
    "\n",
    "#Information Gain\n",
    "Measures['information_gain'] = sp.log(P_ab/(P_a*P_b))/sp.log(2)\n",
    "\n",
    "#Jaccard\n",
    "Measures['jaccard'] = P_ab / (P_a + P_b - P_ab)\n",
    "\n",
    "#Kappa\n",
    "Measures['kappa'] = ( P_bgivena*P_a + P_bprimegivenaprime*P_aprime - P_a*P_b\n",
    "                     - P_aprime*P_bprime ) / ( 1 - P_a*P_b - P_aprime*P_bprime )\n",
    "\n",
    "#Klosgen\n",
    "Measures['klosgen'] = sp.sqrt(P_a) * (P_bgivena - P_b)\n",
    "\n",
    "#Kulczynsky 1\n",
    "Measures['kulczynsky_1'] = P_ab / (P_abprime + P_aprimeb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "Measures = {}\n",
    "\n",
    "#Laplace Correction\n",
    "Measures['laplace_correction'] = (N * P_ab + 1) / (N * P_a + 2)\n",
    "\n",
    "#Least Contradiction\n",
    "Measures['least_contradiction'] = (P_ab - P_abprime) / P_b\n",
    "\n",
    "#Lift\n",
    "Measures['lift'] = P_bgivena / P_b\n",
    "\n",
    "#Loevinger\n",
    "Measures['loevinger'] = 1 - P_abprime / (P_a * P_bprime) #same as certainty factor\n",
    "\n",
    "#Negative Reliability\n",
    "Measures['negative_reliability'] = P_bprimegivenaprime #same as specificity\n",
    "\n",
    "#Novelty\n",
    "Measures['novelty'] = N * (P_ab - P_a * P_b)\n",
    "\n",
    "# Odd Multiplier\n",
    "Measures['odd_multiplier'] = (P_ab * P_bprime) / (P_b * P_abprime)\n",
    "\n",
    "#Odd's Ratio\n",
    "Measures['odds_ratio'] = (P_ab * P_aprimebprime) / (P_abprime * P_aprimeb)\n",
    "\n",
    "#One way support\n",
    "Measures['one_way_support'] = P_bgivena * sp.log(P_bgivena / P_b) / sp.log(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "Measures = {}\n",
    "\n",
    "#Piatetsky - Shapiro\n",
    "Measures['piatetsky_shapiro'] = N * (P_ab - P_a * P_b) #same as novelty\n",
    "\n",
    "#Precision\n",
    "Measures['precision'] = P_bgivena #same as confidence\n",
    "\n",
    "#Prevalence\n",
    "Measures['prevalence'] = P_b\n",
    "\n",
    "#Recall\n",
    "Measures['recall'] = P_agivenb\n",
    "\n",
    "#Relative Risk\n",
    "Measures['relative_risk'] = P_bgivena / P_bgivenaprime\n",
    "\n",
    "#Sebag - Schoenauer\n",
    "Measures['sebag_schoenauer'] = P_ab / P_abprime\n",
    "\n",
    "#Specificity\n",
    "Measures['specificity'] = P_bprimegivenaprime\n",
    "\n",
    "#Support\n",
    "Measures['support'] = P_ab\n",
    "\n",
    "#Yules Q\n",
    "Measures['yules_q'] = (P_ab * P_aprimebprime - P_abprime * P_aprimeb) / (P_ab * P_aprimebprime + P_abprime * P_aprimeb)\n",
    "\n",
    "#Yules Y\n",
    "Measures['yules_y'] = (sp.sqrt(P_ab * P_aprimebprime) - sp.sqrt(P_abprime * P_aprimeb)) / (sp.sqrt(P_ab * P_aprimebprime) + sp.sqrt(P_abprime * P_aprimeb))\n",
    "\n",
    "#Zhang\n",
    "Measures['zhang'] = (P_ab - P_a * P_b) / sp.Max(P_ab*P_bprime, P_b*(P_a - P_ab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Measures = {}\n",
    "#Part 3\n",
    "\n",
    "#Added Value\n",
    "Measures['added_value'] = P_bgivena - P_b\n",
    "\n",
    "#Collective Strength\n",
    "Measures['collective_strength'] = ((P_ab + P_aprimebprime)/(P_a*P_b + P_aprime*P_bprime)) * ((1 - P_a*P_b - P_aprime*P_bprime)/(1 - P_ab - P_aprimebprime))\n",
    "\n",
    "#Confirmed Confidence Causal\n",
    "Measures['confirmed_confidence_causal'] = (P_bgivena + P_aprimegivenbprime)/2 - P_bprimegivena\n",
    "\n",
    "#Dependency\n",
    "Measures['dependency'] = Measures['added_value']\n",
    "\n",
    "#Example Counterexample Rate\n",
    "Measures['example_counterexample_rate'] = 1 - P_abprime/P_ab\n",
    "\n",
    "#Goodman Kruskal\n",
    "Measures['goodman_kruskal'] = (sp.Max(P_ab, P_abprime) + sp.Max(P_aprimeb, P_aprimebprime) + sp.Max(P_ab, P_aprimeb) + sp.Max(P_abprime, P_aprimebprime) - sp.Max(P_a, P_aprime) - sp.Max(P_b, P_bprime)) / (2 - sp.Max(P_a, P_aprime) - sp.Max(P_b, P_bprime))\n",
    "\n",
    "#Implication Index\n",
    "Measures['implication_index'] = sp.sqrt(N) * ((P_abprime - P_a * P_bprime)/(sp.sqrt(P_a * P_bprime)))\n",
    "\n",
    "#J-Measure\n",
    "Measures['j_measure'] = P_ab * (sp.log(P_bgivena/P_b)/sp.log(2)) + P_abprime * (sp.log(P_bprimegivena/P_bprime)/sp.log(2))\n",
    "\n",
    "#Leverage\n",
    "Measures['leverage'] = P_bgivena - P_a * P_b\n",
    "\n",
    "#Mutual Information\n",
    "Measures['mutual_information'] = (P_ab * sp.log(P_ab/(P_a*P_b)) + P_abprime * sp.log(P_abprime/(P_a*P_bprime)) + P_aprimeb * sp.log(P_aprimeb/(P_aprime*P_b)) + P_aprimebprime * sp.log(P_aprimebprime/(P_aprime*P_bprime)))/sp.log(2)\n",
    "\n",
    "#Normalized Mutual Information\n",
    "Measures['normalized_mutual_information'] = Measures['mutual_information']/ ((-P_a*sp.log(P_a) -P_aprime*sp.log(P_aprime))/sp.log(2))\n",
    "\n",
    "#Putative Causal Dependency\n",
    "Measures['putative_causal_dependency'] = (P_bgivena - P_b)/2 + (P_aprimegivenbprime - P_aprime) - (P_bprimegivena - P_bprime) - (P_agivenbprime - P_a)\n",
    "\n",
    "#Two way support\n",
    "Measures['two_way_support'] = P_ab * (sp.log(P_bgivena/P_b)/sp.log(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converts the expression in terms of frequencies\n",
    "def convert_to_freq_expr (expr):\n",
    "    expr_sub = expr.subs({\n",
    "            P_a: (f11+f10)/N,\n",
    "            P_b: (f11+f01)/N,\n",
    "            P_ab: f11/N,\n",
    "            P_abprime: f10/N,\n",
    "            P_aprimeb: f01/N,\n",
    "            P_aprimebprime: f00/N\n",
    "        }).subs({N: f11 + f10 + f01 + f00})\n",
    "    \n",
    "    return sp.factor(expr_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(measure):\n",
    "    return (measure+1)/(measure-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piatetsky-Shapiro Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def P1(measure_expr, return_expr=False):\n",
    "    #Convert measure into an equivalent expression with frequency counts\n",
    "    measure_freqs = convert_to_freq_expr(measure_expr)\n",
    "\n",
    "    #P1 - Measure is 0 if A and B are independent. We choose to relax it to 'constant' rather than 0\n",
    "    value_at_ind = measure_freqs.subs({f00: (f10*f01)/f11})\n",
    "\n",
    "    #If only the expression is asked\n",
    "    if return_expr:\n",
    "        return sp.factor(value_at_ind)\n",
    "    \n",
    "    if value_at_ind.is_constant():\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Piatetsky - Shapiro Properties\n",
    "\n",
    "def p2_eval(expr, N_val, c1_val, c2_val):\n",
    "    c1, c2 = sp.symbols('c1, c2')\n",
    "    expr = expr.subs({N: N_val, c1: c1_val, c2: c2_val})\n",
    "    expr = sp.factor(expr)\n",
    "    \n",
    "    # Applying Frechet inequality for P(A,B)\n",
    "    f11_lower_bound = N_val * max(0, c1_val + c2_val - 1)\n",
    "    f11_upper_bound = N_val * min(c1_val, c2_val)\n",
    "    \n",
    "#     sp.plot(expr, (f11, f11_lower_bound, f11_upper_bound-10))\n",
    "    \n",
    "    check_inc = sp.is_strictly_increasing(expr, interval=sp.Interval(f11_lower_bound, f11_upper_bound, right_open=True))\n",
    "    \n",
    "#     print(c1_val, c2_val, check_inc)\n",
    "    #sometimes the above function cannot function properly. In that case, applying the alternate method\n",
    "    if not check_inc:\n",
    "        check_inc = bool(sp.factor(sp.diff(expr)).subs({f11:(f11_lower_bound+f11_upper_bound) /2 }) > 0) & sp.is_monotonic(expr, interval=sp.Interval(f11_lower_bound, f11_upper_bound, right_open=True, left_open=True))\n",
    "    return check_inc\n",
    "\n",
    "def P2(measure_expr, return_expr=False):\n",
    "    \n",
    "    #Convert measure into an equivalent expression with frequency counts\n",
    "    measure_freqs = convert_to_freq_expr(measure_expr)\n",
    "    \n",
    "    #P2 - Measure monotonically increases with P_ab when P_a and P_b remain the same\n",
    "    c1, c2 = sp.symbols('c1, c2')\n",
    "    \n",
    "    #Function to be checked: only a function of c1, c2, N (assumed constant) and f11\n",
    "    p2_expr = measure_freqs.subs({f00: N - f11 - f01 - f10}).subs({f10: c1*N - f11, f01: c2*N - f11})\n",
    "\n",
    "    #If only the expression is asked\n",
    "    if return_expr:\n",
    "        return sp.factor(p2_expr)\n",
    "    \n",
    "    #Checking numerically if monotonic\n",
    "    c1_vals = np.random.randint(100, size=2)/100\n",
    "    c2_vals = np.random.randint(100, size=3)/100\n",
    "    N_val = 1000\n",
    "    p2_numeric_val = np.alltrue([p2_eval(p2_expr, N_val, i, j) for i in c1_vals for j in c2_vals])\n",
    "\n",
    "    return p2_numeric_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p3_eval(expr, N_val, c1_val, c2_val):\n",
    "\n",
    "    #c1: P(A)/P(B), c2: P(AB) ---> c2 < c1\n",
    "    #exchange values if P(AB) > P(A)\n",
    "    if (c1_val < c2_val):\n",
    "        c1_val, c2_val = c2_val, c1_val\n",
    "        \n",
    "    c1, c2 = sp.symbols('c1, c2')\n",
    "    expr = expr.subs({N: N_val, c1: c1_val, c2: c2_val})\n",
    "    expr = sp.factor(expr)\n",
    "    \n",
    "    # P(A) + P(B) + P(AB) <= 1\n",
    "    # Frechet inequality -> P(A) <= 1 + P(AB) - P(B)\n",
    "    P_upper_bound = min(1, 1 - c1_val + c2_val)\n",
    "    P_lower_bound = c2_val\n",
    "    \n",
    "#     print(c1_val, c2_val, P_lower_bound, P_upper_bound, sp.is_strictly_decreasing(expr, interval=sp.Interval(P_lower_bound,P_upper_bound, left_open=True, right_open=True)), expr)\n",
    "#     sp.plot(expr, (P_a, P_lower_bound, P_upper_bound))\n",
    "    check_inc = sp.is_monotonic(expr, interval=sp.Interval(lower_bound, upper_bound, left_open=True, right_open=True))\n",
    "    return (check_inc & bool(sp.factor(sp.diff(expr)).subs({sp.S('x'): (lower_bound+upper_bound)/2})<0))\n",
    "\n",
    "def P3(measure_expr, return_expr=False):\n",
    "    #Convert measure into an equivalent expression with frequency counts\n",
    "    measure_freqs = convert_to_freq_expr(measure_expr)\n",
    "\n",
    "    c1, c2, x = sp.symbols('c1, c2, x')\n",
    "    \n",
    "    #when P(B) is constant\n",
    "    #c1: P(B) and c2: P(AB)\n",
    "    #x: P(A)\n",
    "    p3_expr_pa = measure_freqs.subs({f00: N - f11 - f01 - f10}).subs({f01: c1*N - f11, f10: x*N-f11, f11: c2*N})\n",
    "    \n",
    "    #when P(A) is constant\n",
    "    #c1: P(A) and c2: P(AB)\n",
    "    #x: P(B)\n",
    "    p3_expr_pb = measure_freqs.subs({f00: N - f11 - f01 - f10}).subs({f10: c1*N - f11, f01: x*N-f11, f11: c2*N})\n",
    "\n",
    "    if return_expr:\n",
    "        return [p3_expr_pa, p3_expr_pb]\n",
    "    \n",
    "    #Checking numerically if monotonic\n",
    "    c1_vals = np.random.randint(100, size=2)/100\n",
    "    c2_vals = np.random.randint(100, size=3)/100\n",
    "    N_val = 1000\n",
    "    p3_numeric_val1 = np.alltrue([p3_eval(p3_expr_pa, N_val, i, j) for i in c1_vals for j in c2_vals])\n",
    "    p3_numeric_val2 = np.alltrue([p3_eval(p3_expr_pb, N_val, i, j) for i in c1_vals for j in c2_vals])\n",
    "\n",
    "    if np.alltrue([p3_numeric_val1, p3_numeric_val2]):\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def props_PS(measure_expr):\n",
    "    \n",
    "    #Convert measure into an equivalent expression with frequency counts\n",
    "#     measure_freqs = convert_to_freq_expr(measure_expr)\n",
    "    \n",
    "    #P1 - Measure is 0 if A and B are independent. We choose to relax it to 'constant' rather than 0\n",
    "\n",
    "    P1_val = P1(measure_expr)\n",
    "    \n",
    "    #P2 - Measure monotonically increases with P_ab when P_a and P_b remain the same\n",
    "    \n",
    "    P2_val = P2(measure_expr)\n",
    "    \n",
    "    #P3 - Measure monotonically decreases with P_a (P_b) when P_ab and P_b (P_a) remain the same\n",
    "    P3_val = P3(measure_expr)\n",
    "    \n",
    "#     print('P1: ', P1_val, sep='')\n",
    "#     print('P2: ', P2_val, sep='')\n",
    "#     print('P3: ', P3_val, sep='')\n",
    "    \n",
    "    return [P1_val, P2_val, P3_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tan & Kumar Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def O1(measure_expr, return_expr=False):\n",
    "    #Convert measure into an equivalent expression with frequency counts\n",
    "    measure_freqs = convert_to_freq_expr(measure_expr)\n",
    "\n",
    "    #intermediate variables\n",
    "    c1, c2 = sp.symbols('c1, c2')\n",
    "    \n",
    "    measure_freqs_1 = sp.factor(measure_freqs.subs({f10: c1, f01: c2}).subs({c1: f01, c2: f10}))\n",
    "    \n",
    "    if return_expr:\n",
    "        return [measure_freqs, measure_freqs_1]\n",
    "    \n",
    "    # Measure is symmetric under variable permutation\n",
    "    if sp.factor(measure_freqs - measure_freqs_1) == 0:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def O2(measure_expr, return_expr=False):\n",
    "    #Convert measure into an equivalent expression with frequency counts\n",
    "    measure_freqs = convert_to_freq_expr(measure_expr)\n",
    "\n",
    "    #intermediate variables\n",
    "    c1, c2, c3, c4 = sp.symbols('c1, c2, c3, c4', positive=True)\n",
    "    \n",
    "    measure_freqs_new = sp.factor(measure_freqs.subs({f11: c1*c3*f11, f10: c1*c4*f10, f01: c2*c3*f01, f00: c2*c4*f00}))\n",
    "    \n",
    "    if return_expr:\n",
    "        return [measure_freqs, measure_freqs_new]\n",
    "    \n",
    "    if sp.factor(measure_freqs - measure_freqs_new) == 0:\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def O3(measure_expr, return_expr=False, ignore_normalization=False):\n",
    "    #Convert measure into an equivalent expression with frequency counts\n",
    "    measure_freqs = convert_to_freq_expr(measure_expr)\n",
    "\n",
    "    #intermediate variables\n",
    "    c1, c2, c3, c4 = sp.symbols('c1, c2, c3, c4')\n",
    "    \n",
    "    measure_freqs_new_row = measure_freqs.subs({f11: c1, f10: c2, f01: c3, f00: c4}).subs({c1: f01, c2: f00, c3: f11, c4: f10})\n",
    "    measure_freqs_new_column = measure_freqs.subs({f11: c1, f10: c2, f01: c3, f00: c4}).subs({c1: f10, c2: f11, c3: f00, c4: f01})    \n",
    "    \n",
    "    if return_expr:\n",
    "        return [measure_freqs, measure_freqs_new_row, measure_freqs_new_column]\n",
    "    \n",
    "    if not ignore_normalization:\n",
    "        #Perform normalization\n",
    "        if sp.factor(normalize(measure_freqs) + normalize(measure_freqs_new_row)) == 0 and sp.factor(normalize(measure_freqs) + normalize(measure_freqs_new_column)) == 0:\n",
    "            return (True, 'Normalized')\n",
    "    if sp.factor(measure_freqs + measure_freqs_new_row) == 0 and sp.factor(measure_freqs + measure_freqs_new_column) == 0:\n",
    "        return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def O4(measure_expr, return_expr=False):\n",
    "    #Convert measure into an equivalent expression with frequency counts\n",
    "    measure_freqs = convert_to_freq_expr(measure_expr)\n",
    "\n",
    "    #intermediate variables\n",
    "    c1, c2, c3, c4 = sp.symbols('c1, c2, c3, c4')\n",
    "    \n",
    "    measure_freqs_new = measure_freqs.subs({f11: c1, f10: c2, f01: c3, f00: c4}).subs({c1: f00, c2: f01, c3: f10, c4: f11})\n",
    "    \n",
    "    if return_expr:\n",
    "        return [measure_freqs, measure_freqs_new]\n",
    "    \n",
    "    if sp.factor(measure_freqs - measure_freqs_new) == 0:\n",
    "        return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def O5(measure_expr, return_expr=False):    \n",
    "\n",
    "    #Convert measure into an equivalent expression with frequency counts\n",
    "    measure_freqs = convert_to_freq_expr(measure_expr)\n",
    "\n",
    "    #intermediate variables\n",
    "    c1 = sp.symbols('c1')\n",
    "    \n",
    "    measure_freqs_new = measure_freqs.subs({f00: f00 + c1})\n",
    "    \n",
    "    if return_expr:\n",
    "        return [measure_freqs, measure_freqs_new]\n",
    "    \n",
    "    if sp.factor(measure_freqs - measure_freqs_new) == 0:\n",
    "        return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def props_TK(measure_expr):\n",
    "    \n",
    "    # O1 : True if measures are symmetric under variable permutation\n",
    "    O1_val = O1(measure_expr)\n",
    "    \n",
    "    # O2: True if measure is invariant under row and column scaling\n",
    "    O2_val = O2(measure_expr)\n",
    "    \n",
    "    # O3: True if measure gives opposite value on row/column inversion\n",
    "    O3_val = O3(measure_expr)\n",
    "    \n",
    "    # O4: True if measure gives same value on row+column inversion = Inversion Invariance\n",
    "    O4_val = O4(measure_expr)\n",
    "    \n",
    "    # O5: True if measure gives same value on perturbing f00 count = Null Invariance\n",
    "    O5_val = O5(measure_expr)\n",
    "    \n",
    "    return [O1_val, O2_val, O3_val, O4_val, O5_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lenca Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Q1(measure_expr, return_expr=False):\n",
    "    #Convert measure into an equivalent expression with frequency counts\n",
    "    measure_freqs = convert_to_freq_expr(measure_expr)\n",
    "\n",
    "    #intermediate variables\n",
    "    c1 = sp.symbols('c1')\n",
    "    \n",
    "    measure_freqs_new = measure_freqs.limit(f10, 0)\n",
    "    \n",
    "    if return_expr:\n",
    "        return [measure_freqs, measure_freqs_new]\n",
    "    \n",
    "    \n",
    "    # Return true if the measure becomes a constant or tends to infinity\n",
    "    if sp.factor(measure_freqs_new).is_constant():\n",
    "        return True\n",
    "    elif sp.factor(measure_freqs_new).args[0] == sp.S.Infinity:\n",
    "        return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def props_L(measure_expr):\n",
    "    \n",
    "    # Q1 : True if measures tend to a constant or infinity on setting f10 -> 0\n",
    "    Q1_val = Q1(measure_expr)\n",
    "    \n",
    "#     # O2: True if measure is invariant under row and column scaling\n",
    "#     O2_val = O2(measure_expr)\n",
    "    \n",
    "#     # O3: True if measure gives opposite value on row/column inversion\n",
    "#     O3_val = O3(measure_expr)\n",
    "    \n",
    "#     # O4: True if measure gives same value on row+column inversion = Inversion Invariance\n",
    "#     O4_val = O4(measure_expr)\n",
    "    \n",
    "#     # O5: True if measure gives same value on perturbing f00 count = Null Invariance\n",
    "#     O5_val = O5(measure_expr)\n",
    "    \n",
    "    return [O1_val, O2_val, O3_val, O4_val, O5_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "False\n",
      "\n",
      "certainty_factor\n",
      "False\n",
      "\n",
      "confidence\n",
      "True\n",
      "\n",
      "confidence_causal\n",
      "False\n",
      "\n",
      "confirm_causal\n",
      "False\n",
      "\n",
      "confirm_descriptive\n",
      "False\n",
      "\n",
      "conviction\n",
      "False\n",
      "\n",
      "cosine\n",
      "True\n",
      "\n",
      "coverage\n",
      "False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in sorted(Measures.keys()):\n",
    "#     if m=='mutual_information' or m=='normalized_mutual_information' or m=='goodman_kruskal':\n",
    "#         continue\n",
    "    print(m)\n",
    "    try:\n",
    "        print(O5(Measures[m]))\n",
    "    except:\n",
    "        continue\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #O5 Evaluation by graph\n",
    "# for m in sorted(Measures.keys()):\n",
    "#     print(m)\n",
    "#     expr = O5(Measures[m], True)\n",
    "\n",
    "#     expr_1 = sp.lambdify((f11,f10,f01,f00), expr[0])\n",
    "#     expr_2 = sp.lambdify((f11,f10,f01,f00,sp.S('c1')), expr[1])\n",
    "\n",
    "#     [f1,f2,f3,f4] = np.random.randint(0,1000, 4)\n",
    "#     plt.figure()\n",
    "#     plt.title(m)\n",
    "\n",
    "#     for c1 in range(1,1000,5):\n",
    "#         plt.scatter(c1, expr_1(f1,f2,f3,f4) - expr_2(f1,f2,f3,f4,c1))\n",
    "\n",
    "#     a = [100*(expr_1(f1,f2,f3,f4) - expr_2(f1,f2,f3,f4,c1))/expr_1(f1,f2,f3,f4)\n",
    "#      for c1 in range(1,100,5)]\n",
    "#     print(a)\n",
    "#     print()\n",
    "# # expr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #O4 Evaluation by graph\n",
    "# for m in sorted(Measures.keys()):\n",
    "#     print(m)\n",
    "#     expr = sp.simplify(O4(Measures[m], True))\n",
    "\n",
    "#     expr_1 = sp.lambdify((f11,f10,f01,f00), expr[0])\n",
    "#     expr_2 = sp.lambdify((f11,f10,f01,f00), expr[1])\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.title(m)\n",
    "#     [plt.scatter(c1, expr_1(c1,c2,c3,c4) - expr_2(c1,c2,c3,c4)) \n",
    "#      for c1 in range(1,10,10) \n",
    "#      for c2 in range(1,10,10) \n",
    "#      for c3 in range(1,10,10) \n",
    "#      for c4 in range(1,100,10)]\n",
    "\n",
    "#     [print(expr_1(c1,c2,c3,c4) - expr_2(c1,c2,c3,c4))\n",
    "#      for c1 in range(1,10,10) \n",
    "#      for c2 in range(1,10,10) \n",
    "#      for c3 in range(1,10,10) \n",
    "#      for c4 in range(1,100,10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #P2 evaluation by graph\n",
    "# expr = sp.simplify(P2(Measures['two_way_support'], True))\n",
    "\n",
    "# # # p2_eval(expr, 1000, 0.36, 0.32)\n",
    "\n",
    "# c1,c2 = 0.6, 0.1\n",
    "# expr_1 = expr.subs({N: 1000, sp.S('c1'): c1, sp.S('c2'): c2})\n",
    "# lower_bound = max(0,(c1 + c2 - 1)*1000)\n",
    "# upper_bound = min(c1,c2)*1000\n",
    "# sp.plot(expr_1, (f11, lower_bound, upper_bound))\n",
    "# check_in = sp.is_monotonic(expr_1, interval=sp.Interval(lower_bound, upper_bound, left_open=True, right_open=True))\n",
    "# print(check_in)\n",
    "\n",
    "\n",
    "# c1,c2 = 0.6, 0.5\n",
    "# expr_2 = expr.subs({N: 1000, sp.S('c1'): c1, sp.S('c2'): c2})\n",
    "# lower_bound = max(0,(c1 + c2 - 1)*1000)\n",
    "# upper_bound = min(c1,c2)*1000\n",
    "# sp.plot(expr_2, (f11, lower_bound, upper_bound))\n",
    "# check_in = sp.is_monotonic(expr_2, interval=sp.Interval(lower_bound, upper_bound, left_open=True, right_open=True))\n",
    "# print(check_in)\n",
    "\n",
    "# expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Plot graphs for P3 evaluation \n",
    "\n",
    "# expr = P3(Measures['leverage'],True)[1]\n",
    "# # # # p3_eval(expr, 1000, 0.36, 0.32)\n",
    "\n",
    "# c1,c2 = 0.61, 0.1\n",
    "# expr_1 = expr.subs({N: 1000, sp.S('c1'): c1, sp.S('c2'): c2})\n",
    "# lower_bound = c2\n",
    "# upper_bound = min(1, 1 - c1 + c2)\n",
    "# sp.plot(expr_1, (sp.S('x'), lower_bound, upper_bound))\n",
    "# check_in = sp.is_monotonic(expr_1, interval=sp.Interval(lower_bound, upper_bound, left_open=True, right_open=True))\n",
    "# print(check_in)\n",
    "\n",
    "# c1,c2 = 0.61, 0.41\n",
    "# expr_2 = expr.subs({N: 1000, sp.S('c1'): c1, sp.S('c2'): c2})\n",
    "# lower_bound = c2\n",
    "# upper_bound = min(1, 1 - c1 + c2)\n",
    "# sp.plot(expr_2, (sp.S('x'), lower_bound, upper_bound))\n",
    "# check_in = sp.is_monotonic(expr_2, interval=sp.Interval(lower_bound, upper_bound, left_open=True, right_open=True))\n",
    "# print(check_in)\n",
    "\n",
    "\n",
    "# # sp.plot(sp.factor(sp.diff(expr)), (P_a, lower_bound, upper_bound))\n",
    "# # check_in = sp.is_monotonic(expr, interval=sp.Interval(lower_bound, upper_bound, left_open=True, right_open=True))\n",
    "# # print(check_in)\n",
    "# # # print(check_in & bool(sp.factor(sp.diff(expr)).subs({sp.S('x'): (lower_bound+upper_bound)/2})<0))\n",
    "# # # # sp.singularities(expr, sp.S('x'))\n",
    "# expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot graphs for P3 evaluation \n",
    "\n",
    "# expr = P3(Measures['leverage'],True)[0]\n",
    "# # # # p3_eval(expr, 1000, 0.36, 0.32)\n",
    "\n",
    "# c1,c2 = 0.61, 0.1\n",
    "# expr_1 = expr.subs({N: 1000, sp.S('c1'): c1, sp.S('c2'): c2})\n",
    "# lower_bound = c2\n",
    "# upper_bound = min(1, 1 - c1 + c2)\n",
    "# sp.plot(expr_1, (sp.S('x'), lower_bound, upper_bound))\n",
    "# check_in = sp.is_monotonic(expr_1, interval=sp.Interval(lower_bound, upper_bound, left_open=True, right_open=True))\n",
    "# print(check_in)\n",
    "\n",
    "# c1,c2 = 0.61, 0.41\n",
    "# expr_2 = expr.subs({N: 1000, sp.S('c1'): c1, sp.S('c2'): c2})\n",
    "# lower_bound = c2\n",
    "# upper_bound = min(1, 1 - c1 + c2)\n",
    "# sp.plot(expr_2, (sp.S('x'), lower_bound, upper_bound))\n",
    "# check_in = sp.is_monotonic(expr_2, interval=sp.Interval(lower_bound, upper_bound, left_open=True, right_open=True))\n",
    "# print(check_in)\n",
    "\n",
    "\n",
    "# # sp.plot(sp.factor(sp.diff(expr)), (P_a, lower_bound, upper_bound))\n",
    "# # check_in = sp.is_monotonic(expr, interval=sp.Interval(lower_bound, upper_bound, left_open=True, right_open=True))\n",
    "# # print(check_in)\n",
    "# # # print(check_in & bool(sp.factor(sp.diff(expr)).subs({sp.S('x'): (lower_bound+upper_bound)/2})<0))\n",
    "# # # # sp.singularities(expr, sp.S('x'))\n",
    "# expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
